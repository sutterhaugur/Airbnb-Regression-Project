{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b1c13c80",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem Report (Name of model (KNN / RF / Boosting / Ensemble); Regression / Classification)\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b9670",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "- This is the template for the code and report on the Prediction Problem assignments.\n",
    "\n",
    "- Your code in steps 1, 3, 4, and 5 will be executed sequentially, and must produce the RMSE / accuracy claimed on Kaggle.\n",
    "\n",
    "- Your code in step 2 will also be executed, and must produce the optimal hyperparameter values used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce7a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e86f05",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06025554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_regression.csv')\n",
    "test_data = pd.read_csv('test_regression.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d4b16",
   "metadata": {},
   "source": [
    "## 1) Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adc06dc",
   "metadata": {},
   "source": [
    "Put the data pre-processing code. You don't need to explain it. You may use the same code from last quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe645b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/pbzn3z4n6kq9sxg167nbz_fh0000gn/T/ipykernel_2785/329708372.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['minimum_maximum_nights'][indexes] = 1125\n",
      "/var/folders/wt/pbzn3z4n6kq9sxg167nbz_fh0000gn/T/ipykernel_2785/329708372.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['number_of_reviews_l30d'][indexes] = 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.919013261795044"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "train_data['host_response_rate'] = train_data.host_response_rate.apply(lambda x: str(x)).apply(lambda x: x.replace('%','')).apply(lambda x: float(x))\n",
    "\n",
    "#host acceptence rate\n",
    "train_data['host_acceptance_rate'] = train_data.host_acceptance_rate.apply(lambda x: str(x)).apply(lambda x: x.replace('%','')).apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "#dummy variable host_has_profile_pic\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['host_has_profile_pic']).rename(columns={'t': 'host_has_profile_pic_t'})], axis = 1)\n",
    "train_data.drop(labels = ['host_has_profile_pic', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#dummy variable host_identity_verified\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['host_identity_verified']).rename(columns={'t': 'host_identity_verified_t'})], axis = 1)\n",
    "train_data.drop(labels = ['host_identity_verified', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#dummy variable host_is_superhost\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['host_is_superhost']).rename(columns={'t': 'host_is_superhost_t'})], axis = 1)\n",
    "train_data.drop(labels = ['host_is_superhost', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#number of bathrooms\n",
    "train_data['Number_of_Bathrooms'] = train_data.bathrooms_text.apply(lambda x: str(x)).apply(lambda x: x.replace('shared baths','').replace('shared bath','').replace('Shared half-bath', '0.5').replace('Private half-bath', '0.5').replace('Half-bath','0.5').replace('private bath','').replace('baths','').replace('bath','')).apply(lambda x: float(x))\n",
    "\n",
    "#classifying bathrooms as private and public\n",
    "train_data['shared_bathroom'] = train_data['bathrooms_text'].str.contains('shared', case=False)\n",
    "train_data['private_bathroom'] = train_data['bathrooms_text'].str.contains('private', case=False)\n",
    "\n",
    "#dummy variable has_availability\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['has_availability']).rename(columns={'t': 'has_availability_t'})], axis = 1)\n",
    "train_data.drop(labels = ['has_availability', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#dummy variable instant_bookable\n",
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['instant_bookable']).rename(columns={'t': 'instant_bookable_t'})], axis = 1)\n",
    "train_data.drop(labels = ['instant_bookable', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#classifying downtown neigborhhods\n",
    "downtown_neighborhoods = ['River North', 'Loop', 'Gold Coast', 'Streeterville', \\\n",
    "                          'South Loop', 'West Loop', 'River West', 'Near North Side']\n",
    "\n",
    "#new column is_downtown\n",
    "train_data['is_downtown']= train_data.host_neighbourhood.isin(downtown_neighborhoods).astype(int)\n",
    "\n",
    "#defining a fucntion to classify a row as other if it is not in the top 42 frequencies of neigborhood\n",
    "def reclassify(row):\n",
    "    if row['neighbourhood_cleansed'] not in (list(train_data.neighbourhood_cleansed.value_counts()[0:42].index)):\n",
    "        row['neighbourhood_cleansed'] = 'other'\n",
    "    else:\n",
    "        row\n",
    "    return(row)\n",
    "\n",
    "#applying the function to train\n",
    "train_data = train_data.apply(reclassify, axis = 1)\n",
    "neigborhood_dummies = pd.get_dummies(train_data['neighbourhood_cleansed'])\n",
    "neigborhood_dummies.columns = neigborhood_dummies.columns.str.replace(' ', '_')\n",
    "train_data = pd.concat([train_data, neigborhood_dummies], axis =1)\n",
    "\n",
    "\n",
    "#converting the datetime columns to numeric\n",
    "train_data['host_since'] = (pd.Timestamp.now() - pd.to_datetime(train_data.host_since)).dt.days\n",
    "train_data['first_review'] = (pd.Timestamp.now() - pd.to_datetime(train_data.first_review)).dt.days\n",
    "train_data['last_review'] = (pd.Timestamp.now() - pd.to_datetime(train_data.last_review)).dt.days\n",
    "\n",
    "#hostresponse time dummies\n",
    "host_response_time_dummies = pd.get_dummies(train_data['host_response_time'])\n",
    "host_response_time_dummies.columns = host_response_time_dummies.columns.str.replace(' ', '_')\n",
    "train_data = pd.concat([train_data, host_response_time_dummies], axis =1)\n",
    "\n",
    "#host_verification dummies\n",
    "host_verifications_dummies = pd.get_dummies(train_data['host_verifications'])\n",
    "host_verifications_dummies.columns = host_verifications_dummies.columns.str.replace(' ', '_')\n",
    "new_columns = ['email_workemail_phone', 'email_phone', 'email', 'phone_workemail', 'phone']\n",
    "host_verifications_dummies.columns = new_columns\n",
    "train_data = pd.concat([train_data, host_verifications_dummies], axis =1)\n",
    "\n",
    "#room type dummies\n",
    "room_type_dummies = pd.get_dummies(train_data['room_type'])\n",
    "room_type_dummies.columns = room_type_dummies.columns.str.replace(' ', '_')\n",
    "train_data = pd.concat([train_data, room_type_dummies], axis =1)\n",
    "\n",
    "#defining a function to reclassify property_types as other of its not in to top twenty freqnecies\n",
    "def reclassify_ptype(row):\n",
    "    if row['property_type'] not in list(train_data.property_type.value_counts()[:20].index):\n",
    "        row['property_type'] = 'other'\n",
    "    else:\n",
    "        row\n",
    "    return(row)\n",
    "\n",
    "#applying the function \n",
    "train_data = train_data.apply(reclassify_ptype, axis = 1)\n",
    "\n",
    "#prop type dummies\n",
    "property_type_dummies = pd.get_dummies(train_data['property_type'])\n",
    "property_type_dummies.columns = property_type_dummies.columns.str.replace(' ', '_')\n",
    "train_data = pd.concat([train_data, property_type_dummies], axis =1)\n",
    "\n",
    "#reassigning an extreme value of minimum_maximum_nights to 1125\n",
    "indexes = list(train_data.minimum_maximum_nights[train_data.minimum_maximum_nights == train_data.minimum_maximum_nights.max()].index)\n",
    "train_data['minimum_maximum_nights'][indexes] = 1125\n",
    "\n",
    "#defining a function to reclassify a host neigborhood if its not in. the top 66 frequencies of neigborhoods\n",
    "def reclassify_host_n(row):\n",
    "    if row['host_neighbourhood'] not in list(train_data.host_neighbourhood.value_counts()[:66].index):\n",
    "        row['host_neighbourhood'] = 'other'\n",
    "    else:\n",
    "        row\n",
    "    return(row)\n",
    "\n",
    "#applying the function across the data\n",
    "train_data = train_data.apply(reclassify_host_n, axis = 1)\n",
    "\n",
    "#dummie variables for host_neighbourhood\n",
    "h_neighbourhood_dummies = pd.get_dummies(train_data['host_neighbourhood'])\n",
    "h_neighbourhood_dummies.columns = 'is_' + h_neighbourhood_dummies.columns.str.replace(' ', '_').str.replace('/', '_')\n",
    "train_data = pd.concat([train_data, h_neighbourhood_dummies], axis =1)\n",
    "\n",
    "train_data['price'] = train_data.price.apply(lambda x: x.replace('$','').replace(',','')).apply(lambda x: float(x))\n",
    "\n",
    "#getting rid of outliers\n",
    "train_data = train_data.loc[train_data.price < 80000]\n",
    "\n",
    "#take log\n",
    "indexes = list(train_data.host_listings_count[train_data.host_listings_count > 50].index)\n",
    "train_data['host_listings_count'][indexes] = 50\n",
    "\n",
    "#take log\n",
    "indexes = list(train_data.host_total_listings_count[train_data.host_total_listings_count > 200].index)\n",
    "train_data['host_total_listings_count'][indexes] = 200\n",
    "\n",
    "\n",
    "indexes = list(train_data.beds[train_data.beds > 15].index)\n",
    "train_data['beds'][indexes] = 15\n",
    "\n",
    "indexes = list(train_data.minimum_minimum_nights[train_data.minimum_minimum_nights > 200].index)\n",
    "train_data['minimum_minimum_nights'][indexes] = 200\n",
    "\n",
    "indexes = list(train_data.minimum_nights_avg_ntm[train_data.minimum_nights_avg_ntm > 400].index)\n",
    "train_data['minimum_nights_avg_ntm'][indexes] = 400\n",
    "\n",
    "#take log\n",
    "indexes = list(train_data.number_of_reviews[train_data.number_of_reviews > 300].index)\n",
    "train_data['number_of_reviews'][indexes] = 300\n",
    "\n",
    "#take log\n",
    "indexes = list(train_data.number_of_reviews_ltm[train_data.number_of_reviews_ltm > 70].index)\n",
    "train_data['number_of_reviews_ltm'][indexes] = 70\n",
    "\n",
    "indexes = list(train_data.number_of_reviews_l30d[train_data.number_of_reviews_l30d > 70].index)\n",
    "train_data['number_of_reviews_l30d'][indexes] = 70\n",
    "\n",
    "indexes = list(train_data.number_of_reviews_l30d[train_data.number_of_reviews_l30d > 70].index)\n",
    "train_data['number_of_reviews_l30d'][indexes] = 70\n",
    "\n",
    "\n",
    "indexes = list(train_data.first_review[train_data.first_review < 0].index)\n",
    "train_data['first_review'][indexes] = 125\n",
    "\n",
    "\n",
    "indexes = list(train_data.last_review[train_data.last_review < 0].index)\n",
    "train_data['last_review'][indexes] = 155\n",
    "\n",
    "\n",
    "indexes = list(train_data.calculated_host_listings_count[train_data.calculated_host_listings_count > 300].index)\n",
    "train_data['calculated_host_listings_count'][indexes] = 95\n",
    "\n",
    "indexes = list(train_data.calculated_host_listings_count_entire_homes[train_data.calculated_host_listings_count_entire_homes > 300].index)\n",
    "train_data['calculated_host_listings_count_entire_homes'][indexes] = 95\n",
    "\n",
    "#take log \n",
    "indexes = list(train_data.reviews_per_month[train_data.reviews_per_month > 10].index)\n",
    "train_data['reviews_per_month'][indexes] = 10\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "end - st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c542bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#host_response_rate\n",
    "test_data['host_response_rate'] = test_data.host_response_rate.apply(lambda x: str(x)).apply(lambda x: x.replace('%','')).apply(lambda x: float(x))\n",
    "\n",
    "#host acceptence rate\n",
    "test_data['host_acceptance_rate'] = test_data.host_acceptance_rate.apply(lambda x: str(x)).apply(lambda x: x.replace('%','')).apply(lambda x: float(x))\n",
    "\n",
    "#dummy variable host_has_profile_pic\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['host_has_profile_pic']).rename(columns={'t': 'host_has_profile_pic_t'})], axis = 1)\n",
    "test_data.drop(labels = ['host_has_profile_pic', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#dummy variable host_identity_verified\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['host_identity_verified']).rename(columns={'t': 'host_identity_verified_t'})], axis = 1)\n",
    "test_data.drop(labels = ['host_identity_verified', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['host_is_superhost']).rename(columns={'t': 'host_is_superhost_t'})], axis = 1)\n",
    "test_data.drop(labels = ['host_is_superhost', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#number of bathrooms\n",
    "test_data['Number_of_Bathrooms'] = test_data.bathrooms_text.apply(lambda x: str(x)).apply(lambda x: x.replace('shared baths','').replace('shared bath','').replace('Shared half-bath', '0.5').replace('Private half-bath', '0.5').replace('Half-bath','0.5').replace('private bath','').replace('baths','').replace('bath','')).apply(lambda x: float(x))\n",
    "\n",
    "#classifying bathrooms as private and public\n",
    "test_data['shared_bathroom'] = test_data['bathrooms_text'].str.contains('shared', case=False)\n",
    "test_data['private_bathroom'] = test_data['bathrooms_text'].str.contains('private', case=False)\n",
    "\n",
    "#dummy variable has_availability\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['has_availability']).rename(columns={'t': 'has_availability_t'})], axis = 1)\n",
    "test_data.drop(labels = ['has_availability', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "#dummy variable instant_bookable\n",
    "test_data = pd.concat([test_data, pd.get_dummies(test_data['instant_bookable']).rename(columns={'t': 'instant_bookable_t'})], axis = 1)\n",
    "test_data.drop(labels = ['instant_bookable', 'f'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#classifying downtown neigborhhods\n",
    "downtown_neighborhoods = ['River North', 'Loop', 'Gold Coast', 'Streeterville', \\\n",
    "                          'South Loop', 'West Loop', 'River West', 'Near North Side']\n",
    "\n",
    "#new column is_downtown\n",
    "test_data['is_downtown']= test_data.host_neighbourhood.isin(downtown_neighborhoods).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#applying the function reclassify to test\n",
    "#getting dummies for neighbourhood_cleansed\n",
    "test_data = test_data.apply(reclassify, axis = 1)\n",
    "neigborhood_dummies_test = pd.get_dummies(test_data['neighbourhood_cleansed'])\n",
    "neigborhood_dummies_test.columns = neigborhood_dummies_test.columns.str.replace(' ', '_')\n",
    "test_data = pd.concat([test_data, neigborhood_dummies_test], axis =1)\n",
    "\n",
    "#converting the datetime columns to numeric\n",
    "test_data['host_since'] = (pd.Timestamp.now() - pd.to_datetime(test_data.host_since)).dt.days\n",
    "test_data['first_review'] = (pd.Timestamp.now() - pd.to_datetime(test_data.first_review)).dt.days\n",
    "test_data['last_review'] = (pd.Timestamp.now() - pd.to_datetime(test_data.last_review)).dt.days\n",
    "\n",
    "\n",
    "#hostresponse time dummies\n",
    "host_response_time_dummies_test = pd.get_dummies(test_data['host_response_time'])\n",
    "host_response_time_dummies_test.columns = host_response_time_dummies_test.columns.str.replace(' ', '_')\n",
    "test_data = pd.concat([test_data, host_response_time_dummies_test], axis =1)\n",
    "\n",
    "#host_verification dummies\n",
    "host_verifications_dummies_test = pd.get_dummies(test_data['host_verifications'])\n",
    "host_verifications_dummies_test.columns = host_verifications_dummies_test.columns.str.replace(' ', '_')\n",
    "new_columns = ['email_workemail_phone', 'email_phone', 'email', 'phone_workemail', 'phone']\n",
    "host_verifications_dummies_test.columns = new_columns\n",
    "test_data = pd.concat([test_data, host_verifications_dummies_test], axis =1)\n",
    "\n",
    "#room type dummies\n",
    "room_type_dummies_test = pd.get_dummies(test_data['room_type'])\n",
    "room_type_dummies_test.columns = room_type_dummies_test.columns.str.replace(' ', '_')\n",
    "test_data = pd.concat([test_data, room_type_dummies_test], axis =1)\n",
    "\n",
    "#applying the function reclassify_ptype\n",
    "test_data = test_data.apply(reclassify_ptype, axis = 1)\n",
    "\n",
    "#prop type dummies\n",
    "property_type_dummies_test = pd.get_dummies(test_data['property_type'])\n",
    "property_type_dummies_test.columns = property_type_dummies_test.columns.str.replace(' ', '_')\n",
    "test_data = pd.concat([test_data, property_type_dummies_test], axis =1)\n",
    "\n",
    "#applying the function reclassify_host_n across the data\n",
    "test_data = test_data.apply(reclassify_host_n, axis = 1)\n",
    "\n",
    "#dummie variables for host_neighbourhood\n",
    "h_neighbourhood_dummies_test = pd.get_dummies(test_data['host_neighbourhood'])\n",
    "h_neighbourhood_dummies_test.columns = 'is_' + h_neighbourhood_dummies_test.columns.str.replace(' ', '_').str.replace('/', '_')\n",
    "test_data = pd.concat([test_data, h_neighbourhood_dummies_test], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3a6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "test_data_numeric = test_data.select_dtypes(include = ['int64', 'float64', 'uint8'])\n",
    "train_data_numeric = train_data.select_dtypes(include = ['int64', 'float64', 'uint8'])\n",
    "\n",
    "test_data_numeric = pd.DataFrame(imputer.fit_transform(test_data_numeric),columns = test_data_numeric.columns)\n",
    "train_data_numeric = pd.DataFrame(imputer.fit_transform(train_data_numeric),columns = train_data_numeric.columns)\n",
    "\n",
    "train_data_numeric.drop(labels = ['Belmont_Cragin', 'Private_room_in_guest_suite', 'is_East_Colorado_Springs'], axis = 1, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fed6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_numeric.drop(columns = ['id', 'host_id', 'price'], axis = 1).drop(columns = ['is_other', 'other'], axis = 1)\n",
    "y = train_data_numeric.price\n",
    "X_test = test_data_numeric.drop(columns = ['id', 'host_id'], axis = 1).drop(columns = ['is_other','other'] , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eaefd",
   "metadata": {},
   "source": [
    "## 2) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9b39b7",
   "metadata": {},
   "source": [
    "### How many attempts did it take you to tune the model hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e33d51",
   "metadata": {},
   "source": [
    "8 or 9 attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f50fd",
   "metadata": {},
   "source": [
    "### Which tuning method did you use (grid search / Bayes search / etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ea3666",
   "metadata": {},
   "source": [
    "Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0da667",
   "metadata": {},
   "source": [
    "### What challenges did you face while tuning the hyperparameters, and what actions did you take to address those challenges?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8149e",
   "metadata": {},
   "source": [
    "It took large amounts of time to search for hyperparameters, so I used RandomizedSearchCV with a small number of iterations to get hyperparameters for me to test, I also fitted an XGBoost model and took the 50 most important features to reduce the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26daac",
   "metadata": {},
   "source": [
    "### How many hours did you spend on hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8149d3",
   "metadata": {},
   "source": [
    "3 or 4 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4abb9",
   "metadata": {},
   "source": [
    "**Paste the hyperparameter tuning code below. You must show at least one hyperparameter tuning procedure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "75237897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1b8893e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(model.feature_importances_, index = list(X_train.columns)).sort_values(ascending = False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62ccd848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Number_of_Bathrooms', 'is_downtown', 'is_River_West', 'Entire_home/apt', 'calculated_host_listings_count_private_rooms', 'accommodates', 'West_Town', 'minimum_minimum_nights', 'Near_North_Side', 'calculated_host_listings_count_entire_homes', 'Rogers_Park', 'number_of_reviews_ltm', 'within_a_day', 'Private_room_in_rental_unit', 'email_phone', 'is_West_Loop_Greektown', 'maximum_minimum_nights', 'review_scores_communication', 'minimum_nights', 'review_scores_rating', 'availability_365', 'Room_in_boutique_hotel', 'host_total_listings_count', 'review_scores_checkin', 'minimum_maximum_nights', 'last_review', 'Room_in_hotel', 'review_scores_location', 'is_Irving_Park', 'latitude', 'host_is_superhost_t', 'maximum_nights_avg_ntm', 'Entire_home', 'review_scores_cleanliness', 'Hotel_room', 'host_since', 'longitude', 'minimum_nights_avg_ntm', 'maximum_maximum_nights', 'Edgewater', 'is_Pulaski_Park', 'Private_room_in_home', 'is_Back_of_the_Yards', 'is_Old_Town', 'is_Garfield_Park', 'Irving_Park', 'calculated_host_listings_count', 'Bridgeport', 'North_Center', 'South_Chicago', 'first_review', 'review_scores_value', 'host_has_profile_pic_t', 'host_acceptance_rate', 'Entire_serviced_apartment', 'phone', 'availability_30', 'email_workemail_phone', 'host_response_rate', 'number_of_reviews_l30d', 'has_availability_t', 'reviews_per_month', 'number_of_reviews', 'Logan_Square', 'Entire_loft', 'beds', 'is_Portage_Park', 'phone_workemail', 'is_Lakeview', 'is_Near_North_Side', 'is_Chicago_Loop', 'availability_60', 'is_West_Town', 'host_listings_count', 'review_scores_accuracy', 'availability_90', 'is_Near_South_Side', 'is_Rush_&_Division', 'within_a_few_hours', 'within_an_hour', 'is_Pilsen', 'is_Hyde_Park', 'Near_West_Side', 'Austin', 'Near_South_Side', 'is_Logan_Square', 'is_West_Loop', 'is_Rogers_Park', 'Lower_West_Side', 'is_Jefferson_Park', 'Woodlawn', 'is_Sheffield_&_DePaul', 'Portage_Park', 'instant_bookable_t', 'Douglas', 'maximum_nights', 'Humboldt_Park', 'is_Washington_Park', 'host_identity_verified_t', 'South_Shore']\n"
     ]
    }
   ],
   "source": [
    "print(list(pred.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f5e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['Number_of_Bathrooms', 'is_downtown', 'is_River_West', 'Entire_home/apt', 'calculated_host_listings_count_private_rooms', 'accommodates', 'West_Town', 'minimum_minimum_nights', 'Near_North_Side', 'calculated_host_listings_count_entire_homes', 'Rogers_Park', 'number_of_reviews_ltm', 'within_a_day', 'Private_room_in_rental_unit', 'email_phone', 'is_West_Loop_Greektown', 'maximum_minimum_nights', 'review_scores_communication', 'minimum_nights', 'review_scores_rating', 'availability_365', 'Room_in_boutique_hotel', 'host_total_listings_count', 'review_scores_checkin', 'minimum_maximum_nights', 'last_review', 'Room_in_hotel', 'review_scores_location', 'is_Irving_Park', 'latitude', 'host_is_superhost_t', 'maximum_nights_avg_ntm', 'Entire_home', 'review_scores_cleanliness', 'Hotel_room', 'host_since', 'longitude', 'minimum_nights_avg_ntm', 'maximum_maximum_nights', 'Edgewater', 'is_Pulaski_Park', 'Private_room_in_home', 'is_Back_of_the_Yards', 'is_Old_Town', 'is_Garfield_Park', 'Irving_Park', 'calculated_host_listings_count', 'Bridgeport', 'North_Center', 'South_Chicago', 'first_review', 'review_scores_value', 'host_has_profile_pic_t', 'host_acceptance_rate', 'Entire_serviced_apartment', 'phone', 'availability_30', 'email_workemail_phone', 'host_response_rate', 'number_of_reviews_l30d', 'has_availability_t', 'reviews_per_month', 'number_of_reviews', 'Logan_Square', 'Entire_loft', 'beds', 'is_Portage_Park', 'phone_workemail', 'is_Lakeview', 'is_Near_North_Side', 'is_Chicago_Loop', 'availability_60', 'is_West_Town', 'host_listings_count', 'review_scores_accuracy', 'availability_90', 'is_Near_South_Side', 'is_Rush_&_Division', 'within_a_few_hours', 'within_an_hour', 'is_Pilsen', 'is_Hyde_Park', 'Near_West_Side', 'Austin', 'Near_South_Side', 'is_Logan_Square', 'is_West_Loop', 'is_Rogers_Park', 'Lower_West_Side', 'is_Jefferson_Park', 'Woodlawn', 'is_Sheffield_&_DePaul', 'Portage_Park', 'instant_bookable_t', 'Douglas', 'maximum_nights', 'Humboldt_Park', 'is_Washington_Park', 'host_identity_verified_t', 'South_Shore']]\n",
    "X_test = X_test[['Number_of_Bathrooms', 'is_downtown', 'is_River_West', 'Entire_home/apt', 'calculated_host_listings_count_private_rooms', 'accommodates', 'West_Town', 'minimum_minimum_nights', 'Near_North_Side', 'calculated_host_listings_count_entire_homes', 'Rogers_Park', 'number_of_reviews_ltm', 'within_a_day', 'Private_room_in_rental_unit', 'email_phone', 'is_West_Loop_Greektown', 'maximum_minimum_nights', 'review_scores_communication', 'minimum_nights', 'review_scores_rating', 'availability_365', 'Room_in_boutique_hotel', 'host_total_listings_count', 'review_scores_checkin', 'minimum_maximum_nights', 'last_review', 'Room_in_hotel', 'review_scores_location', 'is_Irving_Park', 'latitude', 'host_is_superhost_t', 'maximum_nights_avg_ntm', 'Entire_home', 'review_scores_cleanliness', 'Hotel_room', 'host_since', 'longitude', 'minimum_nights_avg_ntm', 'maximum_maximum_nights', 'Edgewater', 'is_Pulaski_Park', 'Private_room_in_home', 'is_Back_of_the_Yards', 'is_Old_Town', 'is_Garfield_Park', 'Irving_Park', 'calculated_host_listings_count', 'Bridgeport', 'North_Center', 'South_Chicago', 'first_review', 'review_scores_value', 'host_has_profile_pic_t', 'host_acceptance_rate', 'Entire_serviced_apartment', 'phone', 'availability_30', 'email_workemail_phone', 'host_response_rate', 'number_of_reviews_l30d', 'has_availability_t', 'reviews_per_month', 'number_of_reviews', 'Logan_Square', 'Entire_loft', 'beds', 'is_Portage_Park', 'phone_workemail', 'is_Lakeview', 'is_Near_North_Side', 'is_Chicago_Loop', 'availability_60', 'is_West_Town', 'host_listings_count', 'review_scores_accuracy', 'availability_90', 'is_Near_South_Side', 'is_Rush_&_Division', 'within_a_few_hours', 'within_an_hour', 'is_Pilsen', 'is_Hyde_Park', 'Near_West_Side', 'Austin', 'Near_South_Side', 'is_Logan_Square', 'is_West_Loop', 'is_Rogers_Park', 'Lower_West_Side', 'is_Jefferson_Park', 'Woodlawn', 'is_Sheffield_&_DePaul', 'Portage_Park', 'instant_bookable_t', 'Douglas', 'maximum_nights', 'Humboldt_Park', 'is_Washington_Park', 'host_identity_verified_t', 'South_Shore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "543d9a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_of_Bathrooms</th>\n",
       "      <th>is_downtown</th>\n",
       "      <th>is_River_West</th>\n",
       "      <th>Entire_home/apt</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>West_Town</th>\n",
       "      <th>minimum_minimum_nights</th>\n",
       "      <th>Near_North_Side</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>...</th>\n",
       "      <th>Woodlawn</th>\n",
       "      <th>is_Sheffield_&amp;_DePaul</th>\n",
       "      <th>Portage_Park</th>\n",
       "      <th>instant_bookable_t</th>\n",
       "      <th>Douglas</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>Humboldt_Park</th>\n",
       "      <th>is_Washington_Park</th>\n",
       "      <th>host_identity_verified_t</th>\n",
       "      <th>South_Shore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4999 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Number_of_Bathrooms  is_downtown  is_River_West  Entire_home/apt  \\\n",
       "0                     1.0          0.0            0.0              0.0   \n",
       "1                     3.0          0.0            0.0              0.0   \n",
       "2                     1.0          0.0            0.0              1.0   \n",
       "3                     1.0          0.0            0.0              1.0   \n",
       "4                     2.0          0.0            0.0              1.0   \n",
       "...                   ...          ...            ...              ...   \n",
       "4994                  1.0          0.0            0.0              0.0   \n",
       "4995                  1.0          0.0            0.0              1.0   \n",
       "4996                  1.0          0.0            0.0              1.0   \n",
       "4997                  1.0          0.0            0.0              1.0   \n",
       "4998                  2.0          0.0            0.0              0.0   \n",
       "\n",
       "      calculated_host_listings_count_private_rooms  accommodates  West_Town  \\\n",
       "0                                              8.0           1.0        0.0   \n",
       "1                                             58.0          12.0        0.0   \n",
       "2                                              0.0           6.0        0.0   \n",
       "3                                              0.0           2.0        0.0   \n",
       "4                                              0.0           6.0        0.0   \n",
       "...                                            ...           ...        ...   \n",
       "4994                                           2.0           2.0        0.0   \n",
       "4995                                           0.0           2.0        0.0   \n",
       "4996                                           0.0           4.0        0.0   \n",
       "4997                                           0.0           4.0        0.0   \n",
       "4998                                           2.0           1.0        0.0   \n",
       "\n",
       "      minimum_minimum_nights  Near_North_Side  \\\n",
       "0                       32.0              0.0   \n",
       "1                       32.0              1.0   \n",
       "2                        2.0              0.0   \n",
       "3                        2.0              0.0   \n",
       "4                        2.0              0.0   \n",
       "...                      ...              ...   \n",
       "4994                     4.0              0.0   \n",
       "4995                     2.0              0.0   \n",
       "4996                     3.0              0.0   \n",
       "4997                    32.0              0.0   \n",
       "4998                    32.0              0.0   \n",
       "\n",
       "      calculated_host_listings_count_entire_homes  ...  Woodlawn  \\\n",
       "0                                             1.0  ...       0.0   \n",
       "1                                             0.0  ...       0.0   \n",
       "2                                             1.0  ...       0.0   \n",
       "3                                            55.0  ...       0.0   \n",
       "4                                            74.0  ...       0.0   \n",
       "...                                           ...  ...       ...   \n",
       "4994                                          0.0  ...       0.0   \n",
       "4995                                          8.0  ...       0.0   \n",
       "4996                                          3.0  ...       0.0   \n",
       "4997                                         95.0  ...       0.0   \n",
       "4998                                          0.0  ...       0.0   \n",
       "\n",
       "      is_Sheffield_&_DePaul  Portage_Park  instant_bookable_t  Douglas  \\\n",
       "0                       0.0           0.0                 0.0      0.0   \n",
       "1                       0.0           0.0                 1.0      0.0   \n",
       "2                       0.0           0.0                 0.0      0.0   \n",
       "3                       0.0           0.0                 1.0      0.0   \n",
       "4                       0.0           0.0                 1.0      0.0   \n",
       "...                     ...           ...                 ...      ...   \n",
       "4994                    0.0           0.0                 0.0      0.0   \n",
       "4995                    0.0           0.0                 0.0      0.0   \n",
       "4996                    0.0           0.0                 0.0      0.0   \n",
       "4997                    0.0           0.0                 0.0      0.0   \n",
       "4998                    0.0           0.0                 0.0      0.0   \n",
       "\n",
       "      maximum_nights  Humboldt_Park  is_Washington_Park  \\\n",
       "0             1125.0            0.0                 0.0   \n",
       "1              365.0            0.0                 0.0   \n",
       "2               45.0            0.0                 0.0   \n",
       "3              180.0            0.0                 0.0   \n",
       "4              365.0            0.0                 0.0   \n",
       "...              ...            ...                 ...   \n",
       "4994            90.0            0.0                 0.0   \n",
       "4995            90.0            0.0                 0.0   \n",
       "4996           180.0            0.0                 0.0   \n",
       "4997          1125.0            0.0                 0.0   \n",
       "4998           365.0            0.0                 0.0   \n",
       "\n",
       "      host_identity_verified_t  South_Shore  \n",
       "0                          1.0          0.0  \n",
       "1                          1.0          0.0  \n",
       "2                          1.0          0.0  \n",
       "3                          1.0          0.0  \n",
       "4                          1.0          0.0  \n",
       "...                        ...          ...  \n",
       "4994                       1.0          0.0  \n",
       "4995                       1.0          0.0  \n",
       "4996                       1.0          0.0  \n",
       "4997                       1.0          0.0  \n",
       "4998                       1.0          0.0  \n",
       "\n",
       "[4999 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4afafd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter values = {'subsample': 0.39, 'reg_lambda': 2, 'n_estimators': 4228, 'max_depth': 30, 'learning_rate': 0.03200000000000001, 'gamma': 30, 'colsample_bytree': 0.39}\n",
      "Time taken =  10  minutes\n",
      "-134.83986975034546\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid = {'max_depth': np.arange(5,105,5),\n",
    "              'learning_rate':np.arange(0.0001,1.0,0.0001),\n",
    "               'reg_lambda':np.arange(0,50),\n",
    "                'n_estimators':np.arange(100,6000),\n",
    "                'gamma':np.arange(0,100),\n",
    "                'subsample': np.arange(0.01,1.01,0.01),\n",
    "                'colsample_bytree': np.arange(0.01,1.01,0.01)}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=model,                                                       \n",
    "                             param_distributions = param_grid, n_iter = 60,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "optimal_params.fit(X_train,y)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Time taken = \", round((time.time()-start_time)/60), \" minutes\")\n",
    "print(optimal_params.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'subsample': 0.19, 'reg_lambda': 9, 'n_estimators': 3353, 'max_depth': 100, 'learning_rate': 0.008199999999999999, 'gamma': 63, 'colsample_bytree': 0.33}\n",
    "#-132.63528229181279 #120\n",
    "\n",
    "#{'subsample': 0.23, 'reg_lambda': 43, 'n_estimators': 2482, 'max_depth': 35, 'learning_rate': 0.036000000000000004, 'gamma': 77, 'colsample_bytree': 0.47000000000000003}\n",
    "#-132.75268904264857 #111\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783828c5",
   "metadata": {},
   "source": [
    "Below are the other iterations run and the other optimal hyperparameters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal parameter values = {'subsample': 0.26, 'reg_lambda': 4, 'n_estimators': 5633, 'max_depth': 10, 'learning_rate': 0.001, 'gamma': 20, 'colsample_bytree': 0.8300000000000001}\n",
    "#-134.64458377049564   (combine this with linear model from last quarter for best score)\n",
    "#114\n",
    "\n",
    "#Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 4, 'n_estimators': 5063, 'max_depth': 35, 'learning_rate': 0.001, 'gamma': 83, 'colsample_bytree': 0.78}\n",
    "#-135.41619435476863\n",
    "#115\n",
    "\n",
    "\n",
    "#Optimal parameter values = {'subsample': 0.49, 'reg_lambda': 0, 'n_estimators': 5901, 'max_depth': 80, 'learning_rate': 0.001, 'gamma': 15, 'colsample_bytree': 0.63}\n",
    "#-136.35907734031733\n",
    "\n",
    "\n",
    "# {'subsample': 0.27, 'reg_lambda': 42, 'n_estimators': 5104, 'max_depth': 40, 'learning_rate': 0.069, 'gamma': 10, 'colsample_bytree': 0.36000000000000004}\n",
    "#-133.13994080966233\n",
    "\n",
    "\n",
    "#{'subsample': 0.64, 'reg_lambda': 22, 'n_estimators': 3662, 'max_depth': 90, 'learning_rate': 0.007200000000000001, 'gamma': 94, 'colsample_bytree': 0.63}\n",
    "#-133.82687284677652\n",
    "\n",
    "\n",
    "#Optimal parameter values = {'subsample': 0.43, 'reg_lambda': 27, 'n_estimators': 4529, 'max_depth': 55, 'learning_rate': 0.0078000000000000005, 'gamma': 86, 'colsample_bytree': 0.26}\n",
    "#-133.0030364875477\n",
    "\n",
    "#Optimal parameter values = {'subsample': 0.49, 'reg_lambda': 48, 'n_estimators': 4465, 'max_depth': 75, 'learning_rate': 0.01, 'gamma': 2, 'colsample_bytree': 0.53}\n",
    "#-132.8240724037667"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc357d",
   "metadata": {},
   "source": [
    "**Paste the optimal hyperparameter values below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dbd86",
   "metadata": {},
   "source": [
    "{'subsample': 0.27, 'reg_lambda': 42, 'n_estimators': 5104, 'max_depth': 40, 'learning_rate': 0.069, 'gamma': 10, 'colsample_bytree': 0.36000000000000004}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104de7",
   "metadata": {},
   "source": [
    "## 3) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a37864",
   "metadata": {},
   "source": [
    "Using the optimal model hyperparameters, train the model, and paste the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6462944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor(subsample = 0.23, reg_lambda = 43, n_estimators = 2482, max_depth = 35, \\\n",
    "                          learning_rate = 0.036, gamma = 77, colsample_bytree = 0.47).fit(X_train,y)\n",
    "\n",
    "prices1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d6954",
   "metadata": {},
   "source": [
    "## 4) Put any ad-hoc steps for further improving model accuracy\n",
    "For example, scaling up or scaling down the predictions, capping predictions, etc.\n",
    "\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6f8fe4",
   "metadata": {},
   "source": [
    "No additional ad-hoc steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c5d42",
   "metadata": {},
   "source": [
    "## 5) Export the predictions in the format required to submit on Kaggle\n",
    "Put code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31202106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gave Kaggle RMSE of 109.21\n",
    "\n",
    "pred = pd.Series(prices1)\n",
    "\n",
    "#pred = (prices1 + prices2)/2\n",
    "\n",
    "\n",
    "df = pd.concat([test_data['id'],pred], axis = 1)\n",
    "df.columns = ['id', 'predicted']\n",
    "df.to_csv('output_file306.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
